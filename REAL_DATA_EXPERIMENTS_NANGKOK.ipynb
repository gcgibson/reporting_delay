{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAFFCAYAAAAtjtBuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0cfe096e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from contextlib import contextmanager\n",
    "import sys, os\n",
    "\n",
    "@contextmanager\n",
    "def suppress_stdout():\n",
    "    with open(os.devnull, \"w\") as devnull:\n",
    "        old_stdout = sys.stdout\n",
    "        sys.stdout = devnull\n",
    "        try:  \n",
    "            yield\n",
    "        finally:\n",
    "            sys.stdout = old_stdout\n",
    "            \n",
    "            \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "plt.rcParams['lines.linewidth']=1\n",
    "plt.rcParams['axes.facecolor']='w'\n",
    "\n",
    "n_t_d = []\n",
    "with open(\"province-biweek_with_delays.csv\") as f:\n",
    "    i = 0\n",
    "    for line in f.readlines():\n",
    "        if i > 0:\n",
    "            n_t_d.append(line.replace(\"\\n\",\"\").split(','))\n",
    "        i+=1\n",
    "\n",
    "n_t_d_1 = []\n",
    "\n",
    "for elm in n_t_d:\n",
    "    if elm[2] == \"10\":\n",
    "        n_t_d_1.append(elm)\n",
    "\n",
    "\n",
    "index_to_dates = {}\n",
    "dates_to_index = {}\n",
    "count = 0\n",
    "for i in [\"2014\",\"2015\",\"2016\"]:\n",
    "    for j in range(1,27):\n",
    "        index_to_dates[count] = str(i)+str(j)\n",
    "        dates_to_index[str(i)+str(j)] = count\n",
    "        count +=1\n",
    "        \n",
    "reporting_matrix = np.zeros((26*3,26*3))\n",
    "\n",
    "for elm in n_t_d_1:\n",
    "    try:\n",
    "        sick_date = elm[0]+elm[1]\n",
    "        report_date = elm[-2] + elm[-1]\n",
    "        cases = elm[3]\n",
    "        reporting_matrix_row = dates_to_index[sick_date] \n",
    "        reporting_matrix_col =  dates_to_index[report_date] \n",
    "        reporting_matrix[reporting_matrix_row,reporting_matrix_col] = int(cases)\n",
    "    except:\n",
    "        pass\n",
    "np.set_printoptions(suppress=True)    #np.set_printoptions(threshold=np.nan)\n",
    "\n",
    "def sim_data(x,y,z):\n",
    "    return reporting_matrix[:y]\n",
    "\n",
    "\n",
    "\n",
    "pos=[]\n",
    "biweek_x_label = []\n",
    "for year in [\"2014\",\"2015\",\"2016\"]:\n",
    "    for j in np.arange(1,27,13):\n",
    "        if j <= 9:\n",
    "               biweek_x_label.append(year + \"0\"+ str(j))\n",
    "\n",
    "        else:\n",
    "               biweek_x_label.append(year +  str(j))\n",
    "        if year == \"2014\":\n",
    "               pos.append(j)\n",
    "        elif year == \"2015\":\n",
    "               pos.append(j+26)\n",
    "        elif year == \"2016\":\n",
    "               pos.append(j+26*2)\n",
    "\n",
    "\n",
    "plt.plot(reporting_matrix.sum(axis=1))\n",
    "plt.xticks(pos, biweek_x_label, rotation='vertical')\n",
    "plt.xlabel(\"\\nDate\")\n",
    "plt.title(\"DHF Incidence in Bangkok\")\n",
    "plt.ylabel(\"Incidence\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayes_estimate_prob(po_data,m2,alphas,LO,N_SIM):\n",
    "    ret_arr = []\n",
    "    phat = alphas/sum(alphas)\n",
    "    for s_ in range(N_SIM):\n",
    "        count = LO\n",
    "        for row in np.arange(LO,0,-1):\n",
    "                tmp_n_t_inf = np.max((m2[s_][(D-row)],po_data[D-row]))\n",
    "                sigma_2_0 = 10\n",
    "                sigma_2 =   tmp_n_t_inf*sum(phat[:row])*(1-sum(phat[:row]))\n",
    "                post_mean = (1.*sigma_2_0/(sigma_2_0+sigma_2))*po_data[D-row] \\\n",
    "                          +(1.*sigma_2/(sigma_2_0+sigma_2))*tmp_n_t_inf\n",
    "                post_var = 1./(1./sigma_2_0 + 1./sigma_2) + .000001\n",
    "                \n",
    "                \n",
    "\n",
    "                ret_arr.append(np.random.normal(post_mean, 25*np.sqrt(post_var),size=100))\n",
    "                count -=1\n",
    "    \n",
    "    return ret_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[0.2, 0.18504349345999999, 0.18018414284114675]\n",
      "(array([0., 0.]), array([-12.,  12.]), array([-12.,  13.]), 0.0)\n",
      "(array([0., 0.]), array([-12.,  11.]), array([-12.,  13.]), 0.0)\n",
      "(array([0., 0.]), array([-11.,  12.]), array([-12.,  12.]), 0.0)\n",
      "(array([0., 0.]), array([-12.,  12.]), array([-12.,  13.]), 1.0)\n",
      "(array([0., 0.]), array([-12.,  12.]), array([-12.,  13.]), 0.0)\n",
      "(0.8, 1.0, 1.0)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[265.4121929228799, 0.4682130161200003, 0.2758960514182528]\n",
      "(array([17., 84.]), array([-11.,  11.]), array([-12.,  12.]), 1.0)\n",
      "(array([0., 0.]), array([-11.,  11.]), array([-11.,  12.]), 0.0)\n",
      "(array([0., 0.]), array([-11.,  11.]), array([-12.,  13.]), 0.0)\n",
      "(array([0., 0.]), array([-11.,  11.]), array([-12.,  12.]), 1.0)\n",
      "(array([0., 0.]), array([-11.,  12.]), array([-12.,  13.]), 0.0)\n",
      "(0.6, 1.0, 1.0)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[5.2, 5.307407418280001, 5.135425687499085]\n",
      "(array([0., 0.]), array([-10.,  11.]), array([-12.,  12.]), 1.0)\n",
      "(array([0., 0.]), array([-11.,  11.]), array([-12.,  12.]), 0.0)\n",
      "(array([0., 0.]), array([-11.,  11.]), array([-12.,  12.]), 0.0)\n",
      "(array([0., 0.]), array([-12.,  11.]), array([-12.,  12.]), 5.0)\n",
      "(array([0., 0.]), array([-11.,  11.]), array([-12.,  12.]), 0.0)\n",
      "(0.6, 1.0, 1.0)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[34.6, 34.71886745855999, 34.315534019818635]\n",
      "(array([0., 0.]), array([-11.,  11.]), array([-12.,  12.]), 5.0)\n",
      "(array([0., 0.]), array([-10.,  11.]), array([-12.,  12.]), 0.0)\n",
      "(array([0., 0.]), array([-10.,  11.]), array([-12.,  12.]), 0.0)\n",
      "(array([0., 0.]), array([-10.,  11.]), array([-12.,  12.]), 12.0)\n",
      "(array([0., 0.]), array([-11.,  11.]), array([-12.,  12.]), 2.0)\n",
      "(0.4, 0.8, 1.0)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[46.0, 45.726751979620005, 45.507218834476966]\n",
      "(array([0., 0.]), array([-12.,  12.]), array([-15.,  15.]), 12.0)\n",
      "(array([0., 0.]), array([-11.,  11.]), array([-15.,  15.]), 2.0)\n",
      "(array([0., 0.]), array([-11.,  12.]), array([-15.,  15.]), 0.0)\n",
      "(array([0., 0.]), array([-12.,  11.]), array([-14.,  15.]), 9.0)\n",
      "(array([0., 0.]), array([-10.,  11.]), array([-15.,  15.]), 1.0)\n",
      "(0.2, 1.0, 1.0)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[81.4, 82.84850926704001, 80.67003200764388]\n",
      "(array([0., 0.]), array([-12.,  10.]), array([-14.,  15.]), 9.0)\n",
      "(array([0., 0.]), array([-12.,  11.]), array([-14.,  15.]), 1.0)\n",
      "(array([0., 0.]), array([-11.,  12.]), array([-15.,  15.]), 0.0)\n",
      "(array([0., 0.]), array([-11.,  11.]), array([-14.,  15.]), 18.0)\n",
      "(array([0., 0.]), array([-11.,  11.]), array([-14.,  15.]), 1.0)\n",
      "(0.2, 0.8, 0.8)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[154.0, 151.33878819334, 152.63154210596085]\n",
      "(array([0., 0.]), array([-14.,  14.]), array([-17.,  17.]), 18.0)\n",
      "(array([0., 0.]), array([-15.,  13.]), array([-17.,  18.]), 1.0)\n",
      "(array([0., 0.]), array([-13.,  13.]), array([-17.,  18.]), 0.0)\n",
      "(array([0., 0.]), array([-12.,  14.]), array([-17.,  18.]), 21.0)\n",
      "(array([0., 0.]), array([-14.,  14.]), array([-17.,  17.]), 2.0)\n",
      "(0.2, 0.6, 0.6)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[8601.35477197313, 271.29348115162, 260.21366640921616]\n",
      "(array([0., 0.]), array([-13.,  15.]), array([-17.,  18.]), 21.0)\n",
      "(array([0., 0.]), array([-13.,  12.]), array([-17.,  18.]), 2.0)\n",
      "(array([0., 0.]), array([-12.,  14.]), array([-17.,  18.]), 0.0)\n",
      "(array([0., 0.]), array([-14.,  14.]), array([-17.,  18.]), 30.0)\n",
      "(array([ 53., 673.]), array([-14.,  14.]), array([-17.,  18.]), 3.0)\n",
      "(0.2, 0.6, 0.6)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[8796.108785596496, 1119.64909919902, 1078.738090333073]\n",
      "(array([0., 0.]), array([-15.,  14.]), array([-17.,  20.]), 30.0)\n",
      "(array([26., 95.]), array([-15.,  15.]), array([-17.,  20.]), 3.0)\n",
      "(array([0., 0.]), array([-15.,  15.]), array([-18.,  20.]), 0.0)\n",
      "(array([0., 0.]), array([-14.,  15.]), array([-18.,  20.]), 68.0)\n",
      "(array([ 53., 683.]), array([-16.,  15.]), array([-18.,  20.]), 7.0)\n",
      "(0.2, 0.6, 0.6)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[20074.248663784056, 1819.4900062155798, 1780.1502368217775]\n",
      "(array([0., 0.]), array([-13.,  14.]), array([-17.,  20.]), 68.0)\n",
      "(array([ 25., 102.]), array([-13.,  13.]), array([-17.,  20.]), 7.0)\n",
      "(array([0., 0.]), array([-13.,  13.]), array([-17.,  19.]), 0.0)\n",
      "(array([0., 0.]), array([-13.,  13.]), array([-17.,  19.]), 67.0)\n",
      "(array([ 89., 987.]), array([-14.,  14.]), array([-17.,  20.]), 7.0)\n",
      "(0.2, 0.6, 0.6)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[9936.09337943183, 2544.1671666091997, 2466.386352226168]\n",
      "(array([0., 0.]), array([-17.,  17.]), array([-18.,  21.]), 67.0)\n",
      "(array([ 38., 145.]), array([-16.,  15.]), array([-18.,  22.]), 7.0)\n",
      "(array([0., 0.]), array([-15.,  15.]), array([-19.,  22.]), 0.0)\n",
      "(array([0., 0.]), array([-16.,  15.]), array([-18.,  21.]), 90.0)\n",
      "(array([ 56., 565.]), array([-16.,  15.]), array([-18.,  21.]), 9.0)\n",
      "(0.2, 0.6, 0.6)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[2196.71421270048, 1847.64802537826, 1831.1221890810798]\n",
      "(array([0., 0.]), array([-18.,  21.]), array([-19.,  22.]), 90.0)\n",
      "(array([27., 95.]), array([-20.,  19.]), array([-19.,  22.]), 9.0)\n",
      "(array([0., 0.]), array([-18.,  18.]), array([-19.,  22.]), 0.0)\n",
      "(array([0., 0.]), array([-18.,  19.]), array([-20.,  22.]), 33.0)\n",
      "(array([0., 0.]), array([-19.,  19.]), array([-19.,  22.]), 6.0)\n",
      "(0.2, 0.6, 0.6)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[22973.928328489237, 559.2061379182002, 547.856755133693]\n",
      "(array([0., 0.]), array([-22.,  22.]), array([-21.,  22.]), 33.0)\n",
      "(array([0., 0.]), array([-24.,  22.]), array([-21.,  22.]), 6.0)\n",
      "(array([0., 0.]), array([-21.,  20.]), array([-21.,  22.]), 0.0)\n",
      "(array([0., 0.]), array([-21.,  23.]), array([-21.,  22.]), 41.0)\n",
      "(array([  88., 1211.]), array([-22.,  23.]), array([-21.,  23.]), 8.0)\n",
      "(0.2, 0.6, 0.6)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[66111.30714596048, 2189.1965889861604, 2073.302569785804]\n",
      "(array([0., 0.]), array([-21.,  21.]), array([-19.,  23.]), 41.0)\n",
      "(array([ 43., 166.]), array([-21.,  20.]), array([-19.,  23.]), 8.0)\n",
      "(array([0., 0.]), array([-22.,  21.]), array([-19.,  23.]), 0.0)\n",
      "(array([0., 0.]), array([-20.,  20.]), array([-19.,  22.]), 95.0)\n",
      "(array([ 159., 1864.]), array([-19.,  21.]), array([-19.,  22.]), 11.0)\n",
      "(0.2, 0.6, 0.6)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[9203.75171305892, 2327.1587340278397, 2309.08908401683]\n",
      "(array([0., 0.]), array([-22.,  26.]), array([-20.,  25.]), 95.0)\n",
      "(array([ 81., 306.]), array([-23.,  24.]), array([-20.,  25.]), 11.0)\n",
      "(array([0., 0.]), array([-24.,  23.]), array([-20.,  25.]), 0.0)\n",
      "(array([0., 0.]), array([-24.,  24.]), array([-20.,  25.]), 53.0)\n",
      "(array([ 36., 432.]), array([-23.,  22.]), array([-20.,  25.]), 8.0)\n",
      "(0.2, 0.6, 0.6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[14506.148338719326, 924.5226677292201, 957.2537333348926]\n",
      "(array([0., 0.]), array([-29.,  34.]), array([-22.,  25.]), 53.0)\n",
      "(array([17., 61.]), array([-28.,  30.]), array([-22.,  25.]), 8.0)\n",
      "(array([0., 0.]), array([-30.,  31.]), array([-22.,  25.]), 0.0)\n",
      "(array([0., 0.]), array([-33.,  32.]), array([-22.,  26.]), 45.0)\n",
      "(array([ 75., 854.]), array([-30.,  29.]), array([-22.,  25.]), 10.0)\n",
      "(0.2, 0.6, 0.6)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[10604.59682581785, 518.3706042780399, 496.53361222623755]\n",
      "(array([0., 0.]), array([-29.,  30.]), array([-22.,  25.]), 45.0)\n",
      "(array([ 33., 105.]), array([-28.,  28.]), array([-22.,  25.]), 10.0)\n",
      "(array([0., 0.]), array([-28.,  27.]), array([-22.,  25.]), 0.0)\n",
      "(array([0., 0.]), array([-26.,  31.]), array([-22.,  25.]), 23.0)\n",
      "(array([ 90., 543.]), array([-28.,  28.]), array([-21.,  25.]), 6.0)\n",
      "(0.2, 0.8, 0.8)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[29883.54374985129, 247.00721197302005, 210.10089874438913]\n",
      "(array([0., 0.]), array([-25.,  30.]), array([-21.,  26.]), 23.0)\n",
      "(array([ 55., 171.]), array([-26.,  29.]), array([-21.,  26.]), 6.0)\n",
      "(array([0., 0.]), array([-28.,  28.]), array([-21.,  26.]), 0.0)\n",
      "(array([0., 0.]), array([-26.,  27.]), array([-21.,  26.]), 25.0)\n",
      "(array([174., 789.]), array([-27.,  27.]), array([-21.,  26.]), 10.0)\n",
      "(0.2, 1.0, 1.0)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[10325.646163994403, 293.74482876644004, 258.79180783573145]\n",
      "(array([0., 0.]), array([-28.,  33.]), array([-23.,  29.]), 25.0)\n",
      "(array([111., 293.]), array([-32.,  29.]), array([-23.,  29.]), 10.0)\n",
      "(array([0., 0.]), array([-27.,  30.]), array([-23.,  29.]), 0.0)\n",
      "(array([0., 0.]), array([-30.,  31.]), array([-23.,  29.]), 28.0)\n",
      "(array([ 80., 272.]), array([-30.,  32.]), array([-23.,  30.]), 8.0)\n",
      "(0.2, 1.0, 1.0)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[25417.076119348185, 183.92385464714002, 205.4770710963275]\n",
      "(array([0., 0.]), array([-40.,  55.]), array([-26.,  33.]), 28.0)\n",
      "(array([ 61., 152.]), array([-36.,  37.]), array([-26.,  34.]), 8.0)\n",
      "(array([0., 0.]), array([-41.,  39.]), array([-26.,  33.]), 0.0)\n",
      "(array([0., 0.]), array([-39.,  39.]), array([-26.,  33.]), 20.0)\n",
      "(array([204., 626.]), array([-36.,  38.]), array([-25.,  34.]), 10.0)\n",
      "(0.2, 1.0, 1.0)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[395374.0796392703, 226.93449025241998, 120.40295043544306]\n",
      "(array([0., 0.]), array([-32.,  39.]), array([-22.,  48.]), 20.0)\n",
      "(array([153., 385.]), array([-32.,  32.]), array([-22.,  48.]), 10.0)\n",
      "(array([0., 0.]), array([-35.,  33.]), array([-22.,  48.]), 0.0)\n",
      "(array([0., 0.]), array([-35.,  30.]), array([-22.,  48.]), 10.0)\n",
      "(array([ 782., 2557.]), array([-33.,  32.]), array([-22.,  48.]), 26.0)\n",
      "(0.2, 1.0, 1.0)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[250187.66623451066, 205.07991944038002, 113.94131200382954]\n",
      "(array([0., 0.]), array([-36.,  59.]), array([-25.,  55.]), 10.0)\n",
      "(array([ 554., 1304.]), array([-40.,  38.]), array([-25.,  55.]), 26.0)\n",
      "(array([0., 0.]), array([-37.,  39.]), array([-25.,  55.]), 0.0)\n",
      "(array([0., 0.]), array([-37.,  37.]), array([-25.,  55.]), 0.0)\n",
      "(array([ 470., 1256.]), array([-38.,  39.]), array([-25.,  55.]), 20.0)\n",
      "(0.4, 1.0, 1.0)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[50224.47916769539, 489.2732818470796, 94.53341998307111]\n",
      "(array([0., 0.]), array([-159.,  269.]), array([-32.,  93.]), 0.0)\n",
      "(array([338., 739.]), array([-78.,  80.]), array([-32.,  93.]), 20.0)\n",
      "(array([0., 0.]), array([-86.,  85.]), array([-32.,  94.]), 0.0)\n",
      "(array([0., 0.]), array([-73.,  83.]), array([-31.,  92.]), 0.0)\n",
      "(array([ 76., 185.]), array([-84.,  82.]), array([-32.,  94.]), 6.0)\n",
      "(0.6, 1.0, 1.0)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[1539.6728106215226, 44.83842601354, 7.895685872954067]\n",
      "(array([0., 0.]), array([-95., 127.]), array([-32.,  49.]), 0.0)\n",
      "(array([ 65., 135.]), array([-65.,  63.]), array([-32.,  49.]), 6.0)\n",
      "(array([0., 0.]), array([-63.,  64.]), array([-32.,  49.]), 0.0)\n",
      "(array([0., 0.]), array([-65.,  64.]), array([-32.,  49.]), 0.0)\n",
      "(array([0., 0.]), array([-62.,  63.]), array([-32.,  48.]), 5.0)\n",
      "(0.6, 1.0, 1.0)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[1551.5304320499972, 10.366086257080003, 6.565069728077003]\n",
      "(array([0., 0.]), array([-42.,  47.]), array([-27.,  33.]), 0.0)\n",
      "(array([ 63., 134.]), array([-41.,  40.]), array([-27.,  32.]), 5.0)\n",
      "(array([0., 0.]), array([-46.,  40.]), array([-27.,  32.]), 0.0)\n",
      "(array([0., 0.]), array([-45.,  42.]), array([-27.,  32.]), 0.0)\n",
      "(array([0., 0.]), array([-42.,  43.]), array([-27.,  32.]), 5.0)\n",
      "(0.6, 1.0, 1.0)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[1328.3110080499996, 8.717815518860005, 4.454861970423955]\n",
      "(array([0., 0.]), array([-33.,  44.]), array([-26.,  32.]), 0.0)\n",
      "(array([ 61., 119.]), array([-38.,  36.]), array([-27.,  32.]), 5.0)\n",
      "(array([0., 0.]), array([-36.,  37.]), array([-26.,  32.]), 0.0)\n",
      "(array([0., 0.]), array([-38.,  38.]), array([-26.,  32.]), 0.0)\n",
      "(array([0., 0.]), array([-36.,  35.]), array([-27.,  32.]), 3.0)\n",
      "(0.6, 1.0, 1.0)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[97.9868817932796, 10.147681566720015, 1.6019498869124686]\n",
      "(array([0., 0.]), array([-29.,  42.]), array([-28.,  32.]), 0.0)\n",
      "(array([18., 35.]), array([-34.,  32.]), array([-28.,  33.]), 3.0)\n",
      "(array([0., 0.]), array([-34.,  34.]), array([-28.,  32.]), 0.0)\n",
      "(array([0., 0.]), array([-36.,  31.]), array([-28.,  32.]), 0.0)\n",
      "(array([0., 0.]), array([-34.,  34.]), array([-29.,  32.]), 2.0)\n",
      "(0.6, 1.0, 1.0)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[58.6, 63.2912291091, 55.21752463496946]\n",
      "(array([0., 0.]), array([-29.,  39.]), array([-27.,  30.]), 0.0)\n",
      "(array([0., 0.]), array([-30.,  29.]), array([-28.,  31.]), 2.0)\n",
      "(array([0., 0.]), array([-30.,  31.]), array([-28.,  31.]), 0.0)\n",
      "(array([0., 0.]), array([-32.,  29.]), array([-27.,  31.]), 0.0)\n",
      "(array([0., 0.]), array([-31.,  31.]), array([-27.,  31.]), 17.0)\n",
      "(0.6, 1.0, 1.0)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[67.6, 65.16369603628, 61.8342518362053]\n",
      "(array([0., 0.]), array([-30.,  37.]), array([-30.,  34.]), 0.0)\n",
      "(array([0., 0.]), array([-32.,  32.]), array([-30.,  34.]), 17.0)\n",
      "(array([0., 0.]), array([-31.,  32.]), array([-30.,  34.]), 0.0)\n",
      "(array([0., 0.]), array([-33.,  33.]), array([-30.,  34.]), 0.0)\n",
      "(array([0., 0.]), array([-28.,  31.]), array([-30.,  33.]), 7.0)\n",
      "(0.6, 1.0, 1.0)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.0, 10.919894991960003, 8.018557693094447]\n",
      "(array([0., 0.]), array([-28.,  34.]), array([-34.,  39.]), 0.0)\n",
      "(array([0., 0.]), array([-31.,  31.]), array([-34.,  40.]), 7.0)\n",
      "(array([0., 0.]), array([-30.,  32.]), array([-34.,  39.]), 0.0)\n",
      "(array([0., 0.]), array([-31.,  30.]), array([-34.,  39.]), 0.0)\n",
      "(array([0., 0.]), array([-29.,  32.]), array([-34.,  39.]), 1.0)\n",
      "(0.6, 1.0, 1.0)\n"
     ]
    }
   ],
   "source": [
    "from scipy.special import expit\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "variance_level_results = []\n",
    "import sys\n",
    "from pydlm import dlm, trend, seasonality, dynamic, autoReg, longSeason\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import os\n",
    "D=26\n",
    "rmse_vec_cv = []\n",
    "#with suppress_stdout():\n",
    "rmse_vec = []\n",
    "sim_data_var = []\n",
    "N_SIM = 1000\n",
    "sim_results_pi = []\n",
    "sim_results_mse = []\n",
    "for sim_num in np.arange(30,60):\n",
    "            sim_n_t_d = sim_data(D,sim_num,False)\n",
    "            train = sim_n_t_d\n",
    "            \n",
    "\n",
    "\n",
    "            train = np.array(train)\n",
    "            train_n_t_d = train.reshape((-1,D))\n",
    "            ts = train_n_t_d.sum(axis=1)\n",
    "            data_to_be_scaled_down  = train_n_t_d[len(ts)-D:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            delayed_data = []\n",
    "            count = D\n",
    "            for i in range(len(data_to_be_scaled_down)):\n",
    "                tmp = data_to_be_scaled_down[i][:count].tolist()\n",
    "                while len(tmp) <D:\n",
    "                    tmp.append(0)\n",
    "                delayed_data.append(tmp)\n",
    "                count -=1 \n",
    "\n",
    "\n",
    "            training_data = np.append(train_n_t_d[:len(ts)-D],delayed_data,axis=0)\n",
    "\n",
    "            k = np.array(train_n_t_d).shape[1 ]\n",
    "            alphas = np.ones(k)\n",
    "\n",
    "            for i in range(len(ts)-D):\n",
    "                alphas += train_n_t_d[i]\n",
    "\n",
    "            \n",
    "           \n",
    "            #######\n",
    "            # MODEL 1: Delay\n",
    "            ########\n",
    "            delay_model_samples = []\n",
    "            for s_ in range(N_SIM):\n",
    "                model_1_delay = []\n",
    "                count = D\n",
    "                p_vec_noise = np.random.dirichlet(alphas)\n",
    "                for i in range(len(delayed_data)):\n",
    "                    delay_forecast = np.sum(delayed_data[i])/np.sum(p_vec_noise[:count])\n",
    "                    model_1_delay.append(np.round(delay_forecast,2))\n",
    "                    count -= 1\n",
    "                delay_model_samples.append(model_1_delay)\n",
    "            \n",
    "            delay_model_samples = np.array(delay_model_samples)\n",
    "            \n",
    "\n",
    "            #######\n",
    "            # MODEL 2 : Forecast\n",
    "            ########\n",
    "            \n",
    "            LO=5\n",
    "            process_training_data = np.append(ts[:len(ts)-D],model_1_delay[:D-LO],axis=0)\n",
    "            from pydlm import dlm, trend, seasonality, dynamic, autoReg, longSeason\n",
    "            myDLM = dlm(process_training_data)\n",
    "           # myDLM = myDLM + seasonality(26, name='7day', w=1.0)\n",
    "            myDLM = myDLM + autoReg(degree=2, data=process_training_data, name='ar2', w=1.0)\n",
    "            myDLM.fit()\n",
    "            (process_model_forecast, predictVar) = myDLM.predictN(N=LO, date=myDLM.n-1)\n",
    "            \n",
    "            #######\n",
    "            # MODEL 2\n",
    "            ########\n",
    "            forecast_model_samples = []\n",
    "            for s_ in range(N_SIM):\n",
    "                model_2_delay = []\n",
    "                count = D\n",
    "                for i in np.arange(LO,0,-1):\n",
    "                    tmp = np.random.normal(process_model_forecast[LO-i],np.sqrt(predictVar[LO-i]))\n",
    "                    model_2_delay.append(np.round(tmp,2))\n",
    "                    count -= 1\n",
    "\n",
    "                forecast_model_samples.append(np.append(model_1_delay[:D-LO],model_2_delay))\n",
    "            \n",
    "            forecast_model_samples = np.array(forecast_model_samples)\n",
    "            \n",
    "                \n",
    "            model_average = bayes_estimate_prob(np.sum(delayed_data,axis=1),forecast_model_samples,alphas,LO,N_SIM)\n",
    "            \n",
    "            model_average = np.transpose(np.array(model_average).reshape((-1,LO)))\n",
    "            delay_model_samples = np.transpose(np.array(delay_model_samples))\n",
    "            forecast_model_samples = np.transpose(np.array(forecast_model_samples))\n",
    "            \n",
    "            delay_sim_res = delay_model_samples\n",
    "            fcast_sim_res = forecast_model_samples\n",
    "            avg_sim_res = model_average\n",
    "            LO_av = avg_sim_res\n",
    "            LO_delay = delay_sim_res[D-LO:]\n",
    "            LO_fcast = fcast_sim_res[D-LO:]\n",
    "            LO_truth = ts[len(ts)-LO:]\n",
    "            \n",
    "            sim_results_mse.append([mean_squared_error(np.mean(LO_delay,axis=1),LO_truth),\\\n",
    "                                   mean_squared_error(np.mean(LO_fcast,axis=1),LO_truth),\\\n",
    "                                   mean_squared_error(np.mean(LO_av,axis=1),LO_truth)])\n",
    "            print (sim_results_mse[-1])\n",
    "            av_cp = 0\n",
    "            fcast_cp = 0\n",
    "            delay_cp = 0\n",
    "            for i in range(LO):\n",
    "                LO_av_ci = np.round(np.percentile(LO_av[i],[2.5,97.5]))\n",
    "                LO_fcast_ci = np.round(np.percentile(LO_fcast[i],[2.5,97.5]))\n",
    "                LO_delay_ci = np.round(np.percentile(LO_delay[i],[2.5,97.5]))\n",
    "                print (LO_delay_ci,LO_fcast_ci,LO_av_ci, LO_truth[i])\n",
    "                if LO_av_ci[0] <= LO_truth[i] <= LO_av_ci[1]:\n",
    "                    av_cp +=1\n",
    "\n",
    "                if LO_fcast_ci[0] <= LO_truth[i] <= LO_fcast_ci[1]:\n",
    "                    fcast_cp +=1\n",
    "\n",
    "                if LO_delay_ci[0] <= LO_truth[i] <= LO_delay_ci[1]:\n",
    "                    delay_cp +=1\n",
    "\n",
    "\n",
    "            av_cp = 1.*av_cp/LO\n",
    "            fcast_cp = 1.*fcast_cp/LO\n",
    "            delay_cp = 1.*delay_cp/LO\n",
    "\n",
    "            print (delay_cp,fcast_cp,av_cp)\n",
    "            sim_results_pi.append([delay_cp,fcast_cp,av_cp])\n",
    "    \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.36666667 0.84666667 0.85333333]\n",
      "[3132.   54.   51.]\n"
     ]
    }
   ],
   "source": [
    "#### sim_results_pi = np.array(sim_results_pi)\n",
    "print np.mean(sim_results_pi,axis=0)\n",
    "\n",
    "sim_results_mse = np.array(sim_results_mse)\n",
    "print np.round(np.mean(sim_results_mse,axis=0)/10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 78, 26)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[1455.3619463585806, 2.64838392456, 1.9742103361758208]\n",
      "(array([ 45., 173.]), array([-11.,  12.]), array([-11.,  12.]), 3.0)\n",
      "(array([0., 0.]), array([-12.,  10.]), array([-11.,  13.]), 0.0)\n",
      "(array([0., 0.]), array([-11.,  11.]), array([-11.,  13.]), 0.0)\n",
      "(array([0., 0.]), array([-11.,  12.]), array([-11.,  12.]), 2.0)\n",
      "(array([0., 0.]), array([-12.,  11.]), array([-11.,  13.]), 0.0)\n",
      "(0.6, 1.0, 1.0)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[2.6, 2.7906447344599994, 2.5472584789144217]\n",
      "(array([0., 0.]), array([-12.,  12.]), array([-11.,  11.]), 3.0)\n",
      "(array([0., 0.]), array([-12.,  12.]), array([-11.,  11.]), 0.0)\n",
      "(array([0., 0.]), array([-11.,  12.]), array([-11.,  11.]), 0.0)\n",
      "(array([0., 0.]), array([-12.,  12.]), array([-11.,  11.]), 2.0)\n",
      "(array([0., 0.]), array([-11.,  12.]), array([-11.,  11.]), 0.0)\n",
      "(0.6, 1.0, 1.0)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[1930.1318089605004, 1.70875123806, 1.4651679326292857]\n",
      "(array([ 48., 188.]), array([-11.,  11.]), array([-11.,  12.]), 0.0)\n",
      "(array([0., 0.]), array([-12.,  11.]), array([-11.,  13.]), 0.0)\n",
      "(array([0., 0.]), array([-11.,  11.]), array([-11.,  12.]), 0.0)\n",
      "(array([0., 0.]), array([-12.,  11.]), array([-11.,  13.]), 3.0)\n",
      "(array([0., 0.]), array([-11.,  11.]), array([-11.,  13.]), 0.0)\n",
      "(0.6, 1.0, 1.0)\n"
     ]
    }
   ],
   "source": [
    "from scipy.special import expit\n",
    "import matplotlib.pyplot as pltq\n",
    "\n",
    "variance_level_results = []\n",
    "import sys\n",
    "from pydlm import dlm, trend, seasonality, dynamic, autoReg, longSeason\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "cv_mse = []\n",
    "season_data = []\n",
    "sim_results_mse = []\n",
    "sim_results_pi = []\n",
    "for i in range(3):\n",
    "    season_data.append(reporting_matrix[i:(i+26)])\n",
    "    \n",
    "season_data = np.array(season_data).reshape((3,-1,26))\n",
    "\n",
    "print (season_data.shape)\n",
    "\n",
    "for season_for_leave_out in np.arange(3):\n",
    "        sim_n_t_d = season_data#[:cutoff]\n",
    "\n",
    "        train = [sim_n_t_d[x] for x in range(3) if x not in [season_for_leave_out]]\n",
    "        test = sim_n_t_d[season_for_leave_out]\n",
    "        \n",
    "        train = np.array(train)\n",
    "        train_n_t_d = train.reshape((-1,D))\n",
    "        ts = train_n_t_d.sum(axis=1)\n",
    "\n",
    "        data_to_be_scaled_down  = test[len(test)-D:]\n",
    "       \n",
    "        delayed_data = []\n",
    "        count = D\n",
    "        for i in range(len(data_to_be_scaled_down)):\n",
    "            tmp = data_to_be_scaled_down[i][:count].tolist()\n",
    "            while len(tmp) <D:\n",
    "                tmp.append(0)\n",
    "            delayed_data.append(tmp)\n",
    "            count -=1 \n",
    "\n",
    "\n",
    "        training_data = np.append(train_n_t_d[:len(ts)-D],delayed_data,axis=0)\n",
    "\n",
    "        k = np.array(train_n_t_d).shape[1 ]\n",
    "        alphas = np.ones(k)\n",
    "\n",
    "        for i in range(len(ts)-D):\n",
    "            alphas += train_n_t_d[i]\n",
    "\n",
    "\n",
    "\n",
    "        #######\n",
    "        # MODEL 1: Delay\n",
    "        ########\n",
    "        delay_model_samples = []\n",
    "        for s_ in range(N_SIM):\n",
    "            model_1_delay = []\n",
    "            count = D\n",
    "            p_vec_noise = np.random.dirichlet(alphas)\n",
    "            for i in range(len(delayed_data)):\n",
    "                delay_forecast = np.sum(delayed_data[i])/np.sum(p_vec_noise[:count])\n",
    "                model_1_delay.append(np.round(delay_forecast,2))\n",
    "                count -= 1\n",
    "            delay_model_samples.append(model_1_delay)\n",
    "\n",
    "        delay_model_samples = np.array(delay_model_samples)\n",
    "\n",
    "\n",
    "        #######\n",
    "        # MODEL 2 : Forecast\n",
    "        ########\n",
    "\n",
    "        LO=5\n",
    "        process_training_data = np.append(ts[:len(ts)-D],model_1_delay[:D-LO],axis=0)\n",
    "        from pydlm import dlm, trend, seasonality, dynamic, autoReg, longSeason\n",
    "        myDLM = dlm(process_training_data)\n",
    "       # myDLM = myDLM + seasonality(26, name='7day', w=1.0)\n",
    "        myDLM = myDLM + autoReg(degree=2, data=process_training_data, name='ar2', w=1.0)\n",
    "        myDLM.fit()\n",
    "        (process_model_forecast, predictVar) = myDLM.predictN(N=LO, date=myDLM.n-1)\n",
    "\n",
    "        #######\n",
    "        # MODEL 2\n",
    "        ########\n",
    "        forecast_model_samples = []\n",
    "        for s_ in range(N_SIM):\n",
    "            model_2_delay = []\n",
    "            count = D\n",
    "            for i in np.arange(LO,0,-1):\n",
    "                tmp = np.random.normal(process_model_forecast[LO-i],np.sqrt(predictVar[LO-i]))\n",
    "                model_2_delay.append(np.round(tmp,2))\n",
    "                count -= 1\n",
    "\n",
    "            forecast_model_samples.append(np.append(model_1_delay[:D-LO],model_2_delay))\n",
    "\n",
    "        forecast_model_samples = np.array(forecast_model_samples)\n",
    "\n",
    "\n",
    "        model_average = bayes_estimate_prob(np.sum(delayed_data,axis=1),forecast_model_samples,alphas,LO,N_SIM)\n",
    "\n",
    "        model_average = np.transpose(np.array(model_average).reshape((-1,LO)))\n",
    "        delay_model_samples = np.transpose(np.array(delay_model_samples))\n",
    "        forecast_model_samples = np.transpose(np.array(forecast_model_samples))\n",
    "\n",
    "        delay_sim_res = delay_model_samples\n",
    "        fcast_sim_res = forecast_model_samples\n",
    "        avg_sim_res = model_average\n",
    "        LO_av = avg_sim_res\n",
    "        LO_delay = delay_sim_res[D-LO:]\n",
    "        LO_fcast = fcast_sim_res[D-LO:]\n",
    "        LO_truth = ts[len(ts)-LO:]\n",
    "\n",
    "        sim_results_mse.append([mean_squared_error(np.mean(LO_delay,axis=1),LO_truth),\\\n",
    "                               mean_squared_error(np.mean(LO_fcast,axis=1),LO_truth),\\\n",
    "                               mean_squared_error(np.mean(LO_av,axis=1),LO_truth)])\n",
    "        print (sim_results_mse[-1])\n",
    "        av_cp = 0\n",
    "        fcast_cp = 0\n",
    "        delay_cp = 0\n",
    "        for i in range(LO):\n",
    "            LO_av_ci = np.round(np.percentile(LO_av[i],[2.5,97.5]))\n",
    "            LO_fcast_ci = np.round(np.percentile(LO_fcast[i],[2.5,97.5]))\n",
    "            LO_delay_ci = np.round(np.percentile(LO_delay[i],[2.5,97.5]))\n",
    "            print (LO_delay_ci,LO_fcast_ci,LO_av_ci, LO_truth[i])\n",
    "            if LO_av_ci[0] <= LO_truth[i] <= LO_av_ci[1]:\n",
    "                av_cp +=1\n",
    "\n",
    "            if LO_fcast_ci[0] <= LO_truth[i] <= LO_fcast_ci[1]:\n",
    "                fcast_cp +=1\n",
    "\n",
    "            if LO_delay_ci[0] <= LO_truth[i] <= LO_delay_ci[1]:\n",
    "                delay_cp +=1\n",
    "\n",
    "\n",
    "        av_cp = 1.*av_cp/LO\n",
    "        fcast_cp = 1.*fcast_cp/LO\n",
    "        delay_cp = 1.*delay_cp/LO\n",
    "\n",
    "        print (delay_cp,fcast_cp,av_cp)\n",
    "        sim_results_pi.append([delay_cp,fcast_cp,av_cp])\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6 1.  1. ]\n",
      "[1129.    2.    2.]\n"
     ]
    }
   ],
   "source": [
    "#### sim_results_pi = np.array(sim_results_pi)\n",
    "print np.mean(sim_results_pi,axis=0)\n",
    "\n",
    "sim_results_mse = np.array(sim_results_mse)\n",
    "print np.round(np.mean(sim_results_mse,axis=0)/1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
