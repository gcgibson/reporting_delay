{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAFFCAYAAAAdAsFPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMmu3EusAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f313a5b0710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from contextlib import contextmanager\n",
    "import sys, os\n",
    "\n",
    "@contextmanager\n",
    "def suppress_stdout():\n",
    "    with open(os.devnull, \"w\") as devnull:\n",
    "        old_stdout = sys.stdout\n",
    "        sys.stdout = devnull\n",
    "        try:  \n",
    "            yield\n",
    "        finally:\n",
    "            sys.stdout = old_stdout\n",
    "            \n",
    "            \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "plt.rcParams['lines.linewidth']=1\n",
    "plt.rcParams['axes.facecolor']='w'\n",
    "\n",
    "n_t_d = []\n",
    "with open(\"province-biweek_with_delays.csv\") as f:\n",
    "    i = 0\n",
    "    for line in f.readlines():\n",
    "        if i > 0:\n",
    "            n_t_d.append(line.replace(\"\\n\",\"\").split(','))\n",
    "        i+=1\n",
    "\n",
    "n_t_d_1 = []\n",
    "\n",
    "for elm in n_t_d:\n",
    "    if elm[2] == \"48\":\n",
    "        n_t_d_1.append(elm)\n",
    "\n",
    "\n",
    "index_to_dates = {}\n",
    "dates_to_index = {}\n",
    "count = 0\n",
    "for i in [\"2014\",\"2015\",\"2016\"]:\n",
    "    for j in range(1,27):\n",
    "        index_to_dates[count] = str(i)+str(j)\n",
    "        dates_to_index[str(i)+str(j)] = count\n",
    "        count +=1\n",
    "        \n",
    "reporting_matrix = np.zeros((26*3,26*3))\n",
    "\n",
    "for elm in n_t_d_1:\n",
    "    try:\n",
    "        sick_date = elm[0]+elm[1]\n",
    "        report_date = elm[-2] + elm[-1]\n",
    "        cases = elm[3]\n",
    "        reporting_matrix_row = dates_to_index[sick_date] \n",
    "        reporting_matrix_col =  dates_to_index[report_date] \n",
    "        reporting_matrix[reporting_matrix_row,reporting_matrix_col] = int(cases)\n",
    "    except:\n",
    "        pass\n",
    "np.set_printoptions(suppress=True)    #np.set_printoptions(threshold=np.nan)\n",
    "\n",
    "def sim_data(x,y,z):\n",
    "    return reporting_matrix[:y]\n",
    "\n",
    "\n",
    "\n",
    "pos=[]\n",
    "biweek_x_label = []\n",
    "for year in [\"2014\",\"2015\",\"2016\"]:\n",
    "    for j in np.arange(1,27,13):\n",
    "        if j <= 9:\n",
    "               biweek_x_label.append(year + \"0\"+ str(j))\n",
    "\n",
    "        else:\n",
    "               biweek_x_label.append(year +  str(j))\n",
    "        if year == \"2014\":\n",
    "               pos.append(j)\n",
    "        elif year == \"2015\":\n",
    "               pos.append(j+26)\n",
    "        elif year == \"2016\":\n",
    "               pos.append(j+26*2)\n",
    "\n",
    "\n",
    "plt.plot(reporting_matrix.sum(axis=1))\n",
    "plt.xticks(pos, biweek_x_label, rotation='vertical')\n",
    "plt.xlabel(\"\\nDate\")\n",
    "plt.title(\"DHF Incidence in Chiang Mai\")\n",
    "plt.ylabel(\"Incidence\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayes_estimate_prob(po_data,m2,alphas,LO,N_SIM):\n",
    "    ret_arr = []\n",
    "    phat = alphas/sum(alphas)\n",
    "    for s_ in range(N_SIM):\n",
    "        count = LO\n",
    "        for row in np.arange(LO,0,-1):\n",
    "                tmp_n_t_inf = np.max((m2[s_][(D-row)],po_data[D-row]))\n",
    "                sigma_2_0 = 10\n",
    "                sigma_2 =   tmp_n_t_inf*sum(phat[:row])*(1-sum(phat[:row]))\n",
    "                post_mean = (1.*sigma_2_0/(sigma_2_0+sigma_2))*po_data[D-row] \\\n",
    "                          +(1.*sigma_2/(sigma_2_0+sigma_2))*tmp_n_t_inf\n",
    "                post_var = 1./(1./sigma_2_0 + 1./sigma_2) + .000001\n",
    "                \n",
    "                \n",
    "\n",
    "                ret_arr.append(np.random.normal(post_mean, 25*np.sqrt(post_var),size=100))\n",
    "                count -=1\n",
    "    \n",
    "    return ret_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[0.2, 0.18504349345999999, 0.18018414284114675]\n",
      "(array([0., 0.]), array([-12.,  12.]), array([-12.,  13.]), 0.0)\n",
      "(array([0., 0.]), array([-12.,  11.]), array([-12.,  13.]), 0.0)\n",
      "(array([0., 0.]), array([-11.,  12.]), array([-12.,  12.]), 0.0)\n",
      "(array([0., 0.]), array([-12.,  12.]), array([-12.,  13.]), 1.0)\n",
      "(array([0., 0.]), array([-12.,  12.]), array([-12.,  13.]), 0.0)\n",
      "(0.8, 1.0, 1.0)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[265.4121929228799, 0.4682130161200003, 0.2758960514182528]\n",
      "(array([17., 84.]), array([-11.,  11.]), array([-12.,  12.]), 1.0)\n",
      "(array([0., 0.]), array([-11.,  11.]), array([-11.,  12.]), 0.0)\n",
      "(array([0., 0.]), array([-11.,  11.]), array([-12.,  13.]), 0.0)\n",
      "(array([0., 0.]), array([-11.,  11.]), array([-12.,  12.]), 1.0)\n",
      "(array([0., 0.]), array([-11.,  12.]), array([-12.,  13.]), 0.0)\n",
      "(0.6, 1.0, 1.0)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[5.2, 5.307407418280001, 5.135425687499085]\n",
      "(array([0., 0.]), array([-10.,  11.]), array([-12.,  12.]), 1.0)\n",
      "(array([0., 0.]), array([-11.,  11.]), array([-12.,  12.]), 0.0)\n",
      "(array([0., 0.]), array([-11.,  11.]), array([-12.,  12.]), 0.0)\n",
      "(array([0., 0.]), array([-12.,  11.]), array([-12.,  12.]), 5.0)\n",
      "(array([0., 0.]), array([-11.,  11.]), array([-12.,  12.]), 0.0)\n",
      "(0.6, 1.0, 1.0)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[34.6, 34.71886745855999, 34.315534019818635]\n",
      "(array([0., 0.]), array([-11.,  11.]), array([-12.,  12.]), 5.0)\n",
      "(array([0., 0.]), array([-10.,  11.]), array([-12.,  12.]), 0.0)\n",
      "(array([0., 0.]), array([-10.,  11.]), array([-12.,  12.]), 0.0)\n",
      "(array([0., 0.]), array([-10.,  11.]), array([-12.,  12.]), 12.0)\n",
      "(array([0., 0.]), array([-11.,  11.]), array([-12.,  12.]), 2.0)\n",
      "(0.4, 0.8, 1.0)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[46.0, 45.726751979620005, 45.507218834476966]\n",
      "(array([0., 0.]), array([-12.,  12.]), array([-15.,  15.]), 12.0)\n",
      "(array([0., 0.]), array([-11.,  11.]), array([-15.,  15.]), 2.0)\n",
      "(array([0., 0.]), array([-11.,  12.]), array([-15.,  15.]), 0.0)\n",
      "(array([0., 0.]), array([-12.,  11.]), array([-14.,  15.]), 9.0)\n",
      "(array([0., 0.]), array([-10.,  11.]), array([-15.,  15.]), 1.0)\n",
      "(0.2, 1.0, 1.0)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[81.4, 82.84850926704001, 80.67003200764388]\n",
      "(array([0., 0.]), array([-12.,  10.]), array([-14.,  15.]), 9.0)\n",
      "(array([0., 0.]), array([-12.,  11.]), array([-14.,  15.]), 1.0)\n",
      "(array([0., 0.]), array([-11.,  12.]), array([-15.,  15.]), 0.0)\n",
      "(array([0., 0.]), array([-11.,  11.]), array([-14.,  15.]), 18.0)\n",
      "(array([0., 0.]), array([-11.,  11.]), array([-14.,  15.]), 1.0)\n",
      "(0.2, 0.8, 0.8)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[154.0, 151.33878819334, 152.63154210596085]\n",
      "(array([0., 0.]), array([-14.,  14.]), array([-17.,  17.]), 18.0)\n",
      "(array([0., 0.]), array([-15.,  13.]), array([-17.,  18.]), 1.0)\n",
      "(array([0., 0.]), array([-13.,  13.]), array([-17.,  18.]), 0.0)\n",
      "(array([0., 0.]), array([-12.,  14.]), array([-17.,  18.]), 21.0)\n",
      "(array([0., 0.]), array([-14.,  14.]), array([-17.,  17.]), 2.0)\n",
      "(0.2, 0.6, 0.6)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[8601.35477197313, 271.29348115162, 260.21366640921616]\n",
      "(array([0., 0.]), array([-13.,  15.]), array([-17.,  18.]), 21.0)\n",
      "(array([0., 0.]), array([-13.,  12.]), array([-17.,  18.]), 2.0)\n",
      "(array([0., 0.]), array([-12.,  14.]), array([-17.,  18.]), 0.0)\n",
      "(array([0., 0.]), array([-14.,  14.]), array([-17.,  18.]), 30.0)\n",
      "(array([ 53., 673.]), array([-14.,  14.]), array([-17.,  18.]), 3.0)\n",
      "(0.2, 0.6, 0.6)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[8796.108785596496, 1119.64909919902, 1078.738090333073]\n",
      "(array([0., 0.]), array([-15.,  14.]), array([-17.,  20.]), 30.0)\n",
      "(array([26., 95.]), array([-15.,  15.]), array([-17.,  20.]), 3.0)\n",
      "(array([0., 0.]), array([-15.,  15.]), array([-18.,  20.]), 0.0)\n",
      "(array([0., 0.]), array([-14.,  15.]), array([-18.,  20.]), 68.0)\n",
      "(array([ 53., 683.]), array([-16.,  15.]), array([-18.,  20.]), 7.0)\n",
      "(0.2, 0.6, 0.6)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[20074.248663784056, 1819.4900062155798, 1780.1502368217775]\n",
      "(array([0., 0.]), array([-13.,  14.]), array([-17.,  20.]), 68.0)\n",
      "(array([ 25., 102.]), array([-13.,  13.]), array([-17.,  20.]), 7.0)\n",
      "(array([0., 0.]), array([-13.,  13.]), array([-17.,  19.]), 0.0)\n",
      "(array([0., 0.]), array([-13.,  13.]), array([-17.,  19.]), 67.0)\n",
      "(array([ 89., 987.]), array([-14.,  14.]), array([-17.,  20.]), 7.0)\n",
      "(0.2, 0.6, 0.6)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[9936.09337943183, 2544.1671666091997, 2466.386352226168]\n",
      "(array([0., 0.]), array([-17.,  17.]), array([-18.,  21.]), 67.0)\n",
      "(array([ 38., 145.]), array([-16.,  15.]), array([-18.,  22.]), 7.0)\n",
      "(array([0., 0.]), array([-15.,  15.]), array([-19.,  22.]), 0.0)\n",
      "(array([0., 0.]), array([-16.,  15.]), array([-18.,  21.]), 90.0)\n",
      "(array([ 56., 565.]), array([-16.,  15.]), array([-18.,  21.]), 9.0)\n",
      "(0.2, 0.6, 0.6)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[2196.71421270048, 1847.64802537826, 1831.1221890810798]\n",
      "(array([0., 0.]), array([-18.,  21.]), array([-19.,  22.]), 90.0)\n",
      "(array([27., 95.]), array([-20.,  19.]), array([-19.,  22.]), 9.0)\n",
      "(array([0., 0.]), array([-18.,  18.]), array([-19.,  22.]), 0.0)\n",
      "(array([0., 0.]), array([-18.,  19.]), array([-20.,  22.]), 33.0)\n",
      "(array([0., 0.]), array([-19.,  19.]), array([-19.,  22.]), 6.0)\n",
      "(0.2, 0.6, 0.6)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[22973.928328489237, 559.2061379182002, 547.856755133693]\n",
      "(array([0., 0.]), array([-22.,  22.]), array([-21.,  22.]), 33.0)\n",
      "(array([0., 0.]), array([-24.,  22.]), array([-21.,  22.]), 6.0)\n",
      "(array([0., 0.]), array([-21.,  20.]), array([-21.,  22.]), 0.0)\n",
      "(array([0., 0.]), array([-21.,  23.]), array([-21.,  22.]), 41.0)\n",
      "(array([  88., 1211.]), array([-22.,  23.]), array([-21.,  23.]), 8.0)\n",
      "(0.2, 0.6, 0.6)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[66111.30714596048, 2189.1965889861604, 2073.302569785804]\n",
      "(array([0., 0.]), array([-21.,  21.]), array([-19.,  23.]), 41.0)\n",
      "(array([ 43., 166.]), array([-21.,  20.]), array([-19.,  23.]), 8.0)\n",
      "(array([0., 0.]), array([-22.,  21.]), array([-19.,  23.]), 0.0)\n",
      "(array([0., 0.]), array([-20.,  20.]), array([-19.,  22.]), 95.0)\n",
      "(array([ 159., 1864.]), array([-19.,  21.]), array([-19.,  22.]), 11.0)\n",
      "(0.2, 0.6, 0.6)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[9203.75171305892, 2327.1587340278397, 2309.08908401683]\n",
      "(array([0., 0.]), array([-22.,  26.]), array([-20.,  25.]), 95.0)\n",
      "(array([ 81., 306.]), array([-23.,  24.]), array([-20.,  25.]), 11.0)\n",
      "(array([0., 0.]), array([-24.,  23.]), array([-20.,  25.]), 0.0)\n",
      "(array([0., 0.]), array([-24.,  24.]), array([-20.,  25.]), 53.0)\n",
      "(array([ 36., 432.]), array([-23.,  22.]), array([-20.,  25.]), 8.0)\n",
      "(0.2, 0.6, 0.6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[14506.148338719326, 924.5226677292201, 957.2537333348926]\n",
      "(array([0., 0.]), array([-29.,  34.]), array([-22.,  25.]), 53.0)\n",
      "(array([17., 61.]), array([-28.,  30.]), array([-22.,  25.]), 8.0)\n",
      "(array([0., 0.]), array([-30.,  31.]), array([-22.,  25.]), 0.0)\n",
      "(array([0., 0.]), array([-33.,  32.]), array([-22.,  26.]), 45.0)\n",
      "(array([ 75., 854.]), array([-30.,  29.]), array([-22.,  25.]), 10.0)\n",
      "(0.2, 0.6, 0.6)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[10604.59682581785, 518.3706042780399, 496.53361222623755]\n",
      "(array([0., 0.]), array([-29.,  30.]), array([-22.,  25.]), 45.0)\n",
      "(array([ 33., 105.]), array([-28.,  28.]), array([-22.,  25.]), 10.0)\n",
      "(array([0., 0.]), array([-28.,  27.]), array([-22.,  25.]), 0.0)\n",
      "(array([0., 0.]), array([-26.,  31.]), array([-22.,  25.]), 23.0)\n",
      "(array([ 90., 543.]), array([-28.,  28.]), array([-21.,  25.]), 6.0)\n",
      "(0.2, 0.8, 0.8)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[29883.54374985129, 247.00721197302005, 210.10089874438913]\n",
      "(array([0., 0.]), array([-25.,  30.]), array([-21.,  26.]), 23.0)\n",
      "(array([ 55., 171.]), array([-26.,  29.]), array([-21.,  26.]), 6.0)\n",
      "(array([0., 0.]), array([-28.,  28.]), array([-21.,  26.]), 0.0)\n",
      "(array([0., 0.]), array([-26.,  27.]), array([-21.,  26.]), 25.0)\n",
      "(array([174., 789.]), array([-27.,  27.]), array([-21.,  26.]), 10.0)\n",
      "(0.2, 1.0, 1.0)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[10325.646163994403, 293.74482876644004, 258.79180783573145]\n",
      "(array([0., 0.]), array([-28.,  33.]), array([-23.,  29.]), 25.0)\n",
      "(array([111., 293.]), array([-32.,  29.]), array([-23.,  29.]), 10.0)\n",
      "(array([0., 0.]), array([-27.,  30.]), array([-23.,  29.]), 0.0)\n",
      "(array([0., 0.]), array([-30.,  31.]), array([-23.,  29.]), 28.0)\n",
      "(array([ 80., 272.]), array([-30.,  32.]), array([-23.,  30.]), 8.0)\n",
      "(0.2, 1.0, 1.0)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[25417.076119348185, 183.92385464714002, 205.4770710963275]\n",
      "(array([0., 0.]), array([-40.,  55.]), array([-26.,  33.]), 28.0)\n",
      "(array([ 61., 152.]), array([-36.,  37.]), array([-26.,  34.]), 8.0)\n",
      "(array([0., 0.]), array([-41.,  39.]), array([-26.,  33.]), 0.0)\n",
      "(array([0., 0.]), array([-39.,  39.]), array([-26.,  33.]), 20.0)\n",
      "(array([204., 626.]), array([-36.,  38.]), array([-25.,  34.]), 10.0)\n",
      "(0.2, 1.0, 1.0)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[395374.0796392703, 226.93449025241998, 120.40295043544306]\n",
      "(array([0., 0.]), array([-32.,  39.]), array([-22.,  48.]), 20.0)\n",
      "(array([153., 385.]), array([-32.,  32.]), array([-22.,  48.]), 10.0)\n",
      "(array([0., 0.]), array([-35.,  33.]), array([-22.,  48.]), 0.0)\n",
      "(array([0., 0.]), array([-35.,  30.]), array([-22.,  48.]), 10.0)\n",
      "(array([ 782., 2557.]), array([-33.,  32.]), array([-22.,  48.]), 26.0)\n",
      "(0.2, 1.0, 1.0)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[250187.66623451066, 205.07991944038002, 113.94131200382954]\n",
      "(array([0., 0.]), array([-36.,  59.]), array([-25.,  55.]), 10.0)\n",
      "(array([ 554., 1304.]), array([-40.,  38.]), array([-25.,  55.]), 26.0)\n",
      "(array([0., 0.]), array([-37.,  39.]), array([-25.,  55.]), 0.0)\n",
      "(array([0., 0.]), array([-37.,  37.]), array([-25.,  55.]), 0.0)\n",
      "(array([ 470., 1256.]), array([-38.,  39.]), array([-25.,  55.]), 20.0)\n",
      "(0.4, 1.0, 1.0)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[50224.47916769539, 489.2732818470796, 94.53341998307111]\n",
      "(array([0., 0.]), array([-159.,  269.]), array([-32.,  93.]), 0.0)\n",
      "(array([338., 739.]), array([-78.,  80.]), array([-32.,  93.]), 20.0)\n",
      "(array([0., 0.]), array([-86.,  85.]), array([-32.,  94.]), 0.0)\n",
      "(array([0., 0.]), array([-73.,  83.]), array([-31.,  92.]), 0.0)\n",
      "(array([ 76., 185.]), array([-84.,  82.]), array([-32.,  94.]), 6.0)\n",
      "(0.6, 1.0, 1.0)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[1539.6728106215226, 44.83842601354, 7.895685872954067]\n",
      "(array([0., 0.]), array([-95., 127.]), array([-32.,  49.]), 0.0)\n",
      "(array([ 65., 135.]), array([-65.,  63.]), array([-32.,  49.]), 6.0)\n",
      "(array([0., 0.]), array([-63.,  64.]), array([-32.,  49.]), 0.0)\n",
      "(array([0., 0.]), array([-65.,  64.]), array([-32.,  49.]), 0.0)\n",
      "(array([0., 0.]), array([-62.,  63.]), array([-32.,  48.]), 5.0)\n",
      "(0.6, 1.0, 1.0)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[1551.5304320499972, 10.366086257080003, 6.565069728077003]\n",
      "(array([0., 0.]), array([-42.,  47.]), array([-27.,  33.]), 0.0)\n",
      "(array([ 63., 134.]), array([-41.,  40.]), array([-27.,  32.]), 5.0)\n",
      "(array([0., 0.]), array([-46.,  40.]), array([-27.,  32.]), 0.0)\n",
      "(array([0., 0.]), array([-45.,  42.]), array([-27.,  32.]), 0.0)\n",
      "(array([0., 0.]), array([-42.,  43.]), array([-27.,  32.]), 5.0)\n",
      "(0.6, 1.0, 1.0)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[1328.3110080499996, 8.717815518860005, 4.454861970423955]\n",
      "(array([0., 0.]), array([-33.,  44.]), array([-26.,  32.]), 0.0)\n",
      "(array([ 61., 119.]), array([-38.,  36.]), array([-27.,  32.]), 5.0)\n",
      "(array([0., 0.]), array([-36.,  37.]), array([-26.,  32.]), 0.0)\n",
      "(array([0., 0.]), array([-38.,  38.]), array([-26.,  32.]), 0.0)\n",
      "(array([0., 0.]), array([-36.,  35.]), array([-27.,  32.]), 3.0)\n",
      "(0.6, 1.0, 1.0)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[97.9868817932796, 10.147681566720015, 1.6019498869124686]\n",
      "(array([0., 0.]), array([-29.,  42.]), array([-28.,  32.]), 0.0)\n",
      "(array([18., 35.]), array([-34.,  32.]), array([-28.,  33.]), 3.0)\n",
      "(array([0., 0.]), array([-34.,  34.]), array([-28.,  32.]), 0.0)\n",
      "(array([0., 0.]), array([-36.,  31.]), array([-28.,  32.]), 0.0)\n",
      "(array([0., 0.]), array([-34.,  34.]), array([-29.,  32.]), 2.0)\n",
      "(0.6, 1.0, 1.0)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[58.6, 63.2912291091, 55.21752463496946]\n",
      "(array([0., 0.]), array([-29.,  39.]), array([-27.,  30.]), 0.0)\n",
      "(array([0., 0.]), array([-30.,  29.]), array([-28.,  31.]), 2.0)\n",
      "(array([0., 0.]), array([-30.,  31.]), array([-28.,  31.]), 0.0)\n",
      "(array([0., 0.]), array([-32.,  29.]), array([-27.,  31.]), 0.0)\n",
      "(array([0., 0.]), array([-31.,  31.]), array([-27.,  31.]), 17.0)\n",
      "(0.6, 1.0, 1.0)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[67.6, 65.16369603628, 61.8342518362053]\n",
      "(array([0., 0.]), array([-30.,  37.]), array([-30.,  34.]), 0.0)\n",
      "(array([0., 0.]), array([-32.,  32.]), array([-30.,  34.]), 17.0)\n",
      "(array([0., 0.]), array([-31.,  32.]), array([-30.,  34.]), 0.0)\n",
      "(array([0., 0.]), array([-33.,  33.]), array([-30.,  34.]), 0.0)\n",
      "(array([0., 0.]), array([-28.,  31.]), array([-30.,  33.]), 7.0)\n",
      "(0.6, 1.0, 1.0)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.0, 10.919894991960003, 8.018557693094447]\n",
      "(array([0., 0.]), array([-28.,  34.]), array([-34.,  39.]), 0.0)\n",
      "(array([0., 0.]), array([-31.,  31.]), array([-34.,  40.]), 7.0)\n",
      "(array([0., 0.]), array([-30.,  32.]), array([-34.,  39.]), 0.0)\n",
      "(array([0., 0.]), array([-31.,  30.]), array([-34.,  39.]), 0.0)\n",
      "(array([0., 0.]), array([-29.,  32.]), array([-34.,  39.]), 1.0)\n",
      "(0.6, 1.0, 1.0)\n"
     ]
    }
   ],
   "source": [
    "from scipy.special import expit\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "variance_level_results = []\n",
    "import sys\n",
    "from pydlm import dlm, trend, seasonality, dynamic, autoReg, longSeason\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import os\n",
    "D=26\n",
    "rmse_vec_cv = []\n",
    "#with suppress_stdout():\n",
    "rmse_vec = []\n",
    "sim_data_var = []\n",
    "N_SIM = 1000\n",
    "sim_results_pi = []\n",
    "sim_results_mse = []\n",
    "for sim_num in np.arange(30,60):\n",
    "            sim_n_t_d = sim_data(D,sim_num,False)\n",
    "            train = sim_n_t_d\n",
    "            \n",
    "\n",
    "\n",
    "            train = np.array(train)\n",
    "            train_n_t_d = train.reshape((-1,D))\n",
    "            ts = train_n_t_d.sum(axis=1)\n",
    "            data_to_be_scaled_down  = train_n_t_d[len(ts)-D:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            delayed_data = []\n",
    "            count = D\n",
    "            for i in range(len(data_to_be_scaled_down)):\n",
    "                tmp = data_to_be_scaled_down[i][:count].tolist()\n",
    "                while len(tmp) <D:\n",
    "                    tmp.append(0)\n",
    "                delayed_data.append(tmp)\n",
    "                count -=1 \n",
    "\n",
    "\n",
    "            training_data = np.append(train_n_t_d[:len(ts)-D],delayed_data,axis=0)\n",
    "\n",
    "            k = np.array(train_n_t_d).shape[1 ]\n",
    "            alphas = np.ones(k)\n",
    "\n",
    "            for i in range(len(ts)-D):\n",
    "                alphas += train_n_t_d[i]\n",
    "\n",
    "            \n",
    "           \n",
    "            #######\n",
    "            # MODEL 1: Delay\n",
    "            ########\n",
    "            delay_model_samples = []\n",
    "            for s_ in range(N_SIM):\n",
    "                model_1_delay = []\n",
    "                count = D\n",
    "                p_vec_noise = np.random.dirichlet(alphas)\n",
    "                for i in range(len(delayed_data)):\n",
    "                    delay_forecast = np.sum(delayed_data[i])/np.sum(p_vec_noise[:count])\n",
    "                    model_1_delay.append(np.round(delay_forecast,2))\n",
    "                    count -= 1\n",
    "                delay_model_samples.append(model_1_delay)\n",
    "            \n",
    "            delay_model_samples = np.array(delay_model_samples)\n",
    "            \n",
    "\n",
    "            #######\n",
    "            # MODEL 2 : Forecast\n",
    "            ########\n",
    "            \n",
    "            LO=5\n",
    "            process_training_data = np.append(ts[:len(ts)-D],model_1_delay[:D-LO],axis=0)\n",
    "            from pydlm import dlm, trend, seasonality, dynamic, autoReg, longSeason\n",
    "            myDLM = dlm(process_training_data)\n",
    "           # myDLM = myDLM + seasonality(26, name='7day', w=1.0)\n",
    "            myDLM = myDLM + autoReg(degree=2, data=process_training_data, name='ar2', w=1.0)\n",
    "            myDLM.fit()\n",
    "            (process_model_forecast, predictVar) = myDLM.predictN(N=LO, date=myDLM.n-1)\n",
    "            \n",
    "            #######\n",
    "            # MODEL 2\n",
    "            ########\n",
    "            forecast_model_samples = []\n",
    "            for s_ in range(N_SIM):\n",
    "                model_2_delay = []\n",
    "                count = D\n",
    "                for i in np.arange(LO,0,-1):\n",
    "                    tmp = np.random.normal(process_model_forecast[LO-i],np.sqrt(predictVar[LO-i]))\n",
    "                    model_2_delay.append(np.round(tmp,2))\n",
    "                    count -= 1\n",
    "\n",
    "                forecast_model_samples.append(np.append(model_1_delay[:D-LO],model_2_delay))\n",
    "            \n",
    "            forecast_model_samples = np.array(forecast_model_samples)\n",
    "            \n",
    "                \n",
    "            model_average = bayes_estimate_prob(np.sum(delayed_data,axis=1),forecast_model_samples,alphas,LO,N_SIM)\n",
    "            \n",
    "            model_average = np.transpose(np.array(model_average).reshape((-1,LO)))\n",
    "            delay_model_samples = np.transpose(np.array(delay_model_samples))\n",
    "            forecast_model_samples = np.transpose(np.array(forecast_model_samples))\n",
    "            \n",
    "            delay_sim_res = delay_model_samples\n",
    "            fcast_sim_res = forecast_model_samples\n",
    "            avg_sim_res = model_average\n",
    "            LO_av = avg_sim_res\n",
    "            LO_delay = delay_sim_res[D-LO:]\n",
    "            LO_fcast = fcast_sim_res[D-LO:]\n",
    "            LO_truth = ts[len(ts)-LO:]\n",
    "            \n",
    "            sim_results_mse.append([mean_squared_error(np.mean(LO_delay,axis=1),LO_truth),\\\n",
    "                                   mean_squared_error(np.mean(LO_fcast,axis=1),LO_truth),\\\n",
    "                                   mean_squared_error(np.mean(LO_av,axis=1),LO_truth)])\n",
    "            print (sim_results_mse[-1])\n",
    "            av_cp = 0\n",
    "            fcast_cp = 0\n",
    "            delay_cp = 0\n",
    "            for i in range(LO):\n",
    "                LO_av_ci = np.round(np.percentile(LO_av[i],[2.5,97.5]))\n",
    "                LO_fcast_ci = np.round(np.percentile(LO_fcast[i],[2.5,97.5]))\n",
    "                LO_delay_ci = np.round(np.percentile(LO_delay[i],[2.5,97.5]))\n",
    "                print (LO_delay_ci,LO_fcast_ci,LO_av_ci, LO_truth[i])\n",
    "                if LO_av_ci[0] <= LO_truth[i] <= LO_av_ci[1]:\n",
    "                    av_cp +=1\n",
    "\n",
    "                if LO_fcast_ci[0] <= LO_truth[i] <= LO_fcast_ci[1]:\n",
    "                    fcast_cp +=1\n",
    "\n",
    "                if LO_delay_ci[0] <= LO_truth[i] <= LO_delay_ci[1]:\n",
    "                    delay_cp +=1\n",
    "\n",
    "\n",
    "            av_cp = 1.*av_cp/LO\n",
    "            fcast_cp = 1.*fcast_cp/LO\n",
    "            delay_cp = 1.*delay_cp/LO\n",
    "\n",
    "            print (delay_cp,fcast_cp,av_cp)\n",
    "            sim_results_pi.append([delay_cp,fcast_cp,av_cp])\n",
    "    \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.36666667 0.84666667 0.85333333]\n",
      "[3132.   54.   51.]\n"
     ]
    }
   ],
   "source": [
    "#### sim_results_pi = np.array(sim_results_pi)\n",
    "print np.mean(sim_results_pi,axis=0)\n",
    "\n",
    "sim_results_mse = np.array(sim_results_mse)\n",
    "print np.round(np.mean(sim_results_mse,axis=0)/10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 78, 26)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[1455.3619463585806, 2.64838392456, 1.9742103361758208]\n",
      "(array([ 45., 173.]), array([-11.,  12.]), array([-11.,  12.]), 3.0)\n",
      "(array([0., 0.]), array([-12.,  10.]), array([-11.,  13.]), 0.0)\n",
      "(array([0., 0.]), array([-11.,  11.]), array([-11.,  13.]), 0.0)\n",
      "(array([0., 0.]), array([-11.,  12.]), array([-11.,  12.]), 2.0)\n",
      "(array([0., 0.]), array([-12.,  11.]), array([-11.,  13.]), 0.0)\n",
      "(0.6, 1.0, 1.0)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[2.6, 2.7906447344599994, 2.5472584789144217]\n",
      "(array([0., 0.]), array([-12.,  12.]), array([-11.,  11.]), 3.0)\n",
      "(array([0., 0.]), array([-12.,  12.]), array([-11.,  11.]), 0.0)\n",
      "(array([0., 0.]), array([-11.,  12.]), array([-11.,  11.]), 0.0)\n",
      "(array([0., 0.]), array([-12.,  12.]), array([-11.,  11.]), 2.0)\n",
      "(array([0., 0.]), array([-11.,  12.]), array([-11.,  11.]), 0.0)\n",
      "(0.6, 1.0, 1.0)\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "Starting backward smoothing...\n",
      "Backward smoothing completed.\n",
      "[1930.1318089605004, 1.70875123806, 1.4651679326292857]\n",
      "(array([ 48., 188.]), array([-11.,  11.]), array([-11.,  12.]), 0.0)\n",
      "(array([0., 0.]), array([-12.,  11.]), array([-11.,  13.]), 0.0)\n",
      "(array([0., 0.]), array([-11.,  11.]), array([-11.,  12.]), 0.0)\n",
      "(array([0., 0.]), array([-12.,  11.]), array([-11.,  13.]), 3.0)\n",
      "(array([0., 0.]), array([-11.,  11.]), array([-11.,  13.]), 0.0)\n",
      "(0.6, 1.0, 1.0)\n"
     ]
    }
   ],
   "source": [
    "from scipy.special import expit\n",
    "import matplotlib.pyplot as pltq\n",
    "\n",
    "variance_level_results = []\n",
    "import sys\n",
    "from pydlm import dlm, trend, seasonality, dynamic, autoReg, longSeason\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "cv_mse = []\n",
    "season_data = []\n",
    "sim_results_mse = []\n",
    "sim_results_pi = []\n",
    "for i in range(3):\n",
    "    season_data.append(reporting_matrix[i:(i+26)])\n",
    "    \n",
    "season_data = np.array(season_data).reshape((3,-1,26))\n",
    "\n",
    "print (season_data.shape)\n",
    "\n",
    "for season_for_leave_out in np.arange(3):\n",
    "        sim_n_t_d = season_data#[:cutoff]\n",
    "\n",
    "        train = [sim_n_t_d[x] for x in range(3) if x not in [season_for_leave_out]]\n",
    "        test = sim_n_t_d[season_for_leave_out]\n",
    "        \n",
    "        train = np.array(train)\n",
    "        train_n_t_d = train.reshape((-1,D))\n",
    "        ts = train_n_t_d.sum(axis=1)\n",
    "\n",
    "        data_to_be_scaled_down  = test[len(test)-D:]\n",
    "       \n",
    "        delayed_data = []\n",
    "        count = D\n",
    "        for i in range(len(data_to_be_scaled_down)):\n",
    "            tmp = data_to_be_scaled_down[i][:count].tolist()\n",
    "            while len(tmp) <D:\n",
    "                tmp.append(0)\n",
    "            delayed_data.append(tmp)\n",
    "            count -=1 \n",
    "\n",
    "\n",
    "        training_data = np.append(train_n_t_d[:len(ts)-D],delayed_data,axis=0)\n",
    "\n",
    "        k = np.array(train_n_t_d).shape[1 ]\n",
    "        alphas = np.ones(k)\n",
    "\n",
    "        for i in range(len(ts)-D):\n",
    "            alphas += train_n_t_d[i]\n",
    "\n",
    "\n",
    "\n",
    "        #######\n",
    "        # MODEL 1: Delay\n",
    "        ########\n",
    "        delay_model_samples = []\n",
    "        for s_ in range(N_SIM):\n",
    "            model_1_delay = []\n",
    "            count = D\n",
    "            p_vec_noise = np.random.dirichlet(alphas)\n",
    "            for i in range(len(delayed_data)):\n",
    "                delay_forecast = np.sum(delayed_data[i])/np.sum(p_vec_noise[:count])\n",
    "                model_1_delay.append(np.round(delay_forecast,2))\n",
    "                count -= 1\n",
    "            delay_model_samples.append(model_1_delay)\n",
    "\n",
    "        delay_model_samples = np.array(delay_model_samples)\n",
    "\n",
    "\n",
    "        #######\n",
    "        # MODEL 2 : Forecast\n",
    "        ########\n",
    "\n",
    "        LO=5\n",
    "        process_training_data = np.append(ts[:len(ts)-D],model_1_delay[:D-LO],axis=0)\n",
    "        from pydlm import dlm, trend, seasonality, dynamic, autoReg, longSeason\n",
    "        myDLM = dlm(process_training_data)\n",
    "       # myDLM = myDLM + seasonality(26, name='7day', w=1.0)\n",
    "        myDLM = myDLM + autoReg(degree=2, data=process_training_data, name='ar2', w=1.0)\n",
    "        myDLM.fit()\n",
    "        (process_model_forecast, predictVar) = myDLM.predictN(N=LO, date=myDLM.n-1)\n",
    "\n",
    "        #######\n",
    "        # MODEL 2\n",
    "        ########\n",
    "        forecast_model_samples = []\n",
    "        for s_ in range(N_SIM):\n",
    "            model_2_delay = []\n",
    "            count = D\n",
    "            for i in np.arange(LO,0,-1):\n",
    "                tmp = np.random.normal(process_model_forecast[LO-i],np.sqrt(predictVar[LO-i]))\n",
    "                model_2_delay.append(np.round(tmp,2))\n",
    "                count -= 1\n",
    "\n",
    "            forecast_model_samples.append(np.append(model_1_delay[:D-LO],model_2_delay))\n",
    "\n",
    "        forecast_model_samples = np.array(forecast_model_samples)\n",
    "\n",
    "\n",
    "        model_average = bayes_estimate_prob(np.sum(delayed_data,axis=1),forecast_model_samples,alphas,LO,N_SIM)\n",
    "\n",
    "        model_average = np.transpose(np.array(model_average).reshape((-1,LO)))\n",
    "        delay_model_samples = np.transpose(np.array(delay_model_samples))\n",
    "        forecast_model_samples = np.transpose(np.array(forecast_model_samples))\n",
    "\n",
    "        delay_sim_res = delay_model_samples\n",
    "        fcast_sim_res = forecast_model_samples\n",
    "        avg_sim_res = model_average\n",
    "        LO_av = avg_sim_res\n",
    "        LO_delay = delay_sim_res[D-LO:]\n",
    "        LO_fcast = fcast_sim_res[D-LO:]\n",
    "        LO_truth = ts[len(ts)-LO:]\n",
    "\n",
    "        sim_results_mse.append([mean_squared_error(np.mean(LO_delay,axis=1),LO_truth),\\\n",
    "                               mean_squared_error(np.mean(LO_fcast,axis=1),LO_truth),\\\n",
    "                               mean_squared_error(np.mean(LO_av,axis=1),LO_truth)])\n",
    "        print (sim_results_mse[-1])\n",
    "        av_cp = 0\n",
    "        fcast_cp = 0\n",
    "        delay_cp = 0\n",
    "        for i in range(LO):\n",
    "            LO_av_ci = np.round(np.percentile(LO_av[i],[2.5,97.5]))\n",
    "            LO_fcast_ci = np.round(np.percentile(LO_fcast[i],[2.5,97.5]))\n",
    "            LO_delay_ci = np.round(np.percentile(LO_delay[i],[2.5,97.5]))\n",
    "            print (LO_delay_ci,LO_fcast_ci,LO_av_ci, LO_truth[i])\n",
    "            if LO_av_ci[0] <= LO_truth[i] <= LO_av_ci[1]:\n",
    "                av_cp +=1\n",
    "\n",
    "            if LO_fcast_ci[0] <= LO_truth[i] <= LO_fcast_ci[1]:\n",
    "                fcast_cp +=1\n",
    "\n",
    "            if LO_delay_ci[0] <= LO_truth[i] <= LO_delay_ci[1]:\n",
    "                delay_cp +=1\n",
    "\n",
    "\n",
    "        av_cp = 1.*av_cp/LO\n",
    "        fcast_cp = 1.*fcast_cp/LO\n",
    "        delay_cp = 1.*delay_cp/LO\n",
    "\n",
    "        print (delay_cp,fcast_cp,av_cp)\n",
    "        sim_results_pi.append([delay_cp,fcast_cp,av_cp])\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6 1.  1. ]\n",
      "[1129.    2.    2.]\n"
     ]
    }
   ],
   "source": [
    "#### sim_results_pi = np.array(sim_results_pi)\n",
    "print np.mean(sim_results_pi,axis=0)\n",
    "\n",
    "sim_results_mse = np.array(sim_results_mse)\n",
    "print np.round(np.mean(sim_results_mse,axis=0)/1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
